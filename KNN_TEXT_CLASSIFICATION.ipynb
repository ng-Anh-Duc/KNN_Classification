{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1i5rf3PSQ0mW"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"góp gió gặt bão\",\n",
        "    \"có làm mới có ăn\",\n",
        "    \"đất lành chim đậu\",\n",
        "    \"ăn cháo đá bát\",\n",
        "    \"gậy ông đập lưng ông\",\n",
        "    \"qua cầu rút ván\"\n",
        "]\n",
        "\n",
        "n_doc = len(corpus)\n",
        "#1: positive; 0: negative\n",
        "labels = [1, 1, 1, 0, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array(corpus)\n",
        "y = np.array(labels)"
      ],
      "metadata": {
        "id": "68RmRTK2RBFT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caculate_tfidf(X_vectorized):\n",
        "    tf = np.log(X_vectorized + 1)\n",
        "    df = np.sum(X_vectorized, axis= 0)\n",
        "    idf = np.log((n_doc+1)/(df+1)) + 1\n",
        "    tfidf = tf * idf\n",
        "\n",
        "    return idf, tf, tfidf\n",
        "\n",
        "def compute_norm(tfidf_vec):\n",
        "    norm = np.linalg.norm(tfidf_vec, axis = 1)\n",
        "    n_doc = tfidf_vec.shape[0]\n",
        "    for i in range(n_doc):\n",
        "        tfidf_vec[i] /=  norm[i]"
      ],
      "metadata": {
        "id": "TatBLCafRPDQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "metadata": {
        "id": "DLr6y2DiRgFS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X_vectorized = vectorizer.fit_transform(X).toarray()\n",
        "print(\"Vocab: \", vectorizer.get_feature_names_out())\n",
        "X_vectorized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAiOSjGPRs3x",
        "outputId": "d3f80336-3cf9-427b-afe0-9216dc77726d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab:  ['bát' 'bão' 'chim' 'cháo' 'có' 'cầu' 'gió' 'góp' 'gậy' 'gặt' 'làm' 'lành'\n",
            " 'lưng' 'mới' 'qua' 'rút' 'ván' 'ông' 'ăn' 'đá' 'đất' 'đập' 'đậu']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0],\n",
              "       [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        1],\n",
              "       [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1,\n",
              "        0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using TF-IDF\n",
        "X_idf, X_tf, X_tfidf = caculate_tfidf(X_vectorized)\n",
        "compute_norm(X_tfidf)"
      ],
      "metadata": {
        "id": "Pf8aFmysSLYF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_cls = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_cls.fit(X_tfidf, y)\n",
        "preds = knn_cls.predict(X_tfidf)\n",
        "print(preds)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G36d_PDRSZI5",
        "outputId": "a2869bd8-5458-4b27-b894-dbe29859bca8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 1 1 1]\n",
            "[1 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using sklearn pipeline\n",
        "\n",
        "text_clf_model = Pipeline([('vect', CountVectorizer()),\n",
        "                            ('tfidf', TfidfTransformer()),\n",
        "                            ('clf', KNeighborsClassifier(n_neighbors=1))])\n",
        "\n",
        "text_clf_model.fit(X, y)\n",
        "\n",
        "test_text = np.array([\"cái nết đánh chết cái đẹp\"])\n",
        "preds = text_clf_model.predict(test_text)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3G-oO78Stb5",
        "outputId": "83508b31-17d5-4fe2-922b-664f8c6a984c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mk2TaLEIVdQK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}